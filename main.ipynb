{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from natsort import natsorted\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(file):\n",
    "    if 'txt' in file:\n",
    "        with open(f'Articles/'+file, 'r', encoding='latin1') as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for file in os.listdir('Articles'):\n",
    "    documents.append(read_files(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Phase $:-$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_docs = []\n",
    "for document in documents:\n",
    "    token_docs.append(word_tokenize(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove in , to from stop words\n",
    "#### Add some extra punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.remove('in')\n",
    "stop_words.remove('to')\n",
    "\n",
    "stop_words.extend([\".\", \",\", \"'\", \"-\", \"_\", \":\", \"(\", \")\", \"&\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for token in token_docs:\n",
    "    each_token = []\n",
    "    for term in token:\n",
    "        if term not in stop_words:\n",
    "            each_token.append(term)\n",
    "    documents.append(each_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['antony', 'brutus', 'caeser', 'cleopatra', 'mercy', 'worser']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second phase $:-$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement function to do all steps in first phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(doc):\n",
    "    token_docs = word_tokenize(doc)\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.remove('in')\n",
    "    stop_words.remove('to')\n",
    "    stop_words.remove('where')\n",
    "    stop_words.extend([\".\", \",\", \"'\", \"-\", \"_\", \":\", \"(\", \")\", \"&\", \"/\", \"\\\\\", \"]\", \"[\", \"''\", '\"\"', \"' '\", '\" \"'])\n",
    "    prepared_doc = []\n",
    "    for term in token_docs:\n",
    "        if term not in stop_words:\n",
    "            prepared_doc.append(term)\n",
    "    return prepared_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stemmer.\n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "# Initialize the file no.\n",
    "fileno = 1\n",
    " \n",
    "# Initialize the dictionary.\n",
    "pos_index = {}\n",
    " \n",
    "# Initialize the file mapping (fileno -> file name).\n",
    "file_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.txt', '2.txt', '3.txt', '4.txt', '5.txt', '6.txt', '7.txt', '8.txt', '9.txt', '10.txt']\n"
     ]
    }
   ],
   "source": [
    "# Open files.\n",
    "file_names = natsorted(os.listdir(\"Articles\"))\n",
    "print(file_names)\n",
    "# For every file.\n",
    "for file_name in file_names:\n",
    "\n",
    "    # Read file contents.\n",
    "    with open(f'Articles/{file_name}', 'r', encoding='latin1') as f:\n",
    "        stuff = f.read()\n",
    "    # This is the list of words in order of the text.\n",
    "    # We need to preserve the order because we require positions.\n",
    "    # 'preprocessing' function does some basic punctuation removal,\n",
    "    # stopword removal etc.\n",
    "    final_token_list = preprocessing(stuff)\n",
    "\n",
    "    # For position and term in the tokens.\n",
    "    for pos, term in enumerate(final_token_list):\n",
    "        # print(pos, '-->' ,term)\n",
    "        # First stem the term.\n",
    "        term = stemmer.stem(term)\n",
    "        # print(term)\n",
    "        # If term already exists in the positional index dictionary.\n",
    "        if term in pos_index:\n",
    "                \n",
    "            # Increment total freq by 1.\n",
    "            pos_index[term][0] = pos_index[term][0] + 1\n",
    "                \n",
    "            # Check if the term has existed in that DocID before.\n",
    "            if fileno in pos_index[term][1]:\n",
    "                pos_index[term][1][fileno].append(pos)\n",
    "                    \n",
    "            else:\n",
    "                pos_index[term][1][fileno] = [pos]\n",
    "\n",
    "        # If term does not exist in the positional index dictionary\n",
    "        # (first encounter).\n",
    "        else:\n",
    "                \n",
    "            # Initialize the list.\n",
    "            pos_index[term] = []\n",
    "            # The total frequency is 1.\n",
    "            pos_index[term].append(1)\n",
    "            # The postings list is initially empty.\n",
    "            pos_index[term].append({})     \n",
    "            # Add doc ID to postings list.\n",
    "            pos_index[term][1][fileno] = [pos]\n",
    "\n",
    "    # Map the file no. to the file name.\n",
    "    file_map[fileno] = \"test/\" + file_name\n",
    "\n",
    "    # Increment the file no. counter for document ID mapping             \n",
    "    fileno += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### displays each term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'antoni': [3, {1: [0], 2: [0], 6: [0]}],\n",
       " 'brutu': [3, {1: [1], 2: [1], 4: [0]}],\n",
       " 'caeser': [5, {1: [2], 2: [2], 4: [1], 5: [0], 6: [1]}],\n",
       " 'cleopatra': [1, {1: [3]}],\n",
       " 'merci': [5, {1: [4], 3: [0], 4: [2], 5: [1], 6: [2]}],\n",
       " 'worser': [4, {1: [5], 3: [1], 4: [3], 5: [2]}],\n",
       " 'calpurnia': [1, {2: [3]}],\n",
       " 'angel': [3, {7: [0], 8: [0], 9: [0]}],\n",
       " 'fool': [4, {7: [1], 8: [1], 9: [1], 10: [0]}],\n",
       " 'fear': [3, {7: [2], 8: [2], 10: [1]}],\n",
       " 'in': [4, {7: [3], 8: [3], 9: [2], 10: [2]}],\n",
       " 'rush': [4, {7: [4], 8: [4], 9: [3], 10: [3]}],\n",
       " 'to': [4, {7: [5], 8: [5], 9: [4], 10: [4]}],\n",
       " 'tread': [4, {7: [6], 8: [6], 9: [5], 10: [5]}],\n",
       " 'where': [4, {7: [7], 8: [7], 9: [6], 10: [6]}]}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allow users to write phrase query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term : worser \n",
      "Count : 4\n",
      "1 : [5]\n",
      "3 : [1]\n",
      "4 : [3]\n",
      "5 : [2]\n"
     ]
    }
   ],
   "source": [
    "test_term = input()\n",
    "test_pos_index = pos_index[test_term]\n",
    "print('Term :', test_term, '\\nCount :', test_pos_index[0])\n",
    "for doc in test_pos_index[1]:\n",
    "    print(doc, ':', test_pos_index[1][doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third phase $:-$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "files = os.listdir('Articles')\n",
    "for file in range(1, 11):\n",
    "    documents.append(\" \".join(preprocessing(read_files(str(file)+'.txt'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms = []\n",
    "for doc in documents:\n",
    "    for term in doc.split():\n",
    "        all_terms.append(term)\n",
    "all_terms = set(all_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency\n",
    "$$ tf = \\frac{number of times the term appears in a document} {otal number of words in the document}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(document):\n",
    "    wordDict = dict.fromkeys(all_terms, 0)\n",
    "    for word in document.split():\n",
    "        wordDict[word]+=1\n",
    "    return wordDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pd.DataFrame(get_tf(documents[0]).values(), index=get_tf(documents[0]).keys())\n",
    "for i in range(1, len(documents)):\n",
    "    tf[i] = get_tf(documents[i]).values()\n",
    "tf.columns = ['doc'+str(i) for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>doc6</th>\n",
       "      <th>doc7</th>\n",
       "      <th>doc8</th>\n",
       "      <th>doc9</th>\n",
       "      <th>doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
       "fear          0     0     0     0     0     0     1     1     0      1\n",
       "angels        0     0     0     0     0     0     1     1     1      0\n",
       "caeser        1     1     0     1     1     1     0     0     0      0\n",
       "tread         0     0     0     0     0     0     1     1     1      1\n",
       "fools         0     0     0     0     0     0     1     1     1      1\n",
       "brutus        1     1     0     1     0     0     0     0     0      0\n",
       "in            0     0     0     0     0     0     1     1     1      1\n",
       "antony        1     1     0     0     0     1     0     0     0      0\n",
       "to            0     0     0     0     0     0     1     1     1      1\n",
       "rush          0     0     0     0     0     0     1     1     1      1\n",
       "mercy         1     0     1     1     1     1     0     0     0      0\n",
       "worser        1     0     1     1     1     0     0     0     0      0\n",
       "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
       "where         0     0     0     0     0     0     1     1     1      1\n",
       "calpurnia     0     1     0     0     0     0     0     0     0      0"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency\n",
    "$$ idf = \\frac{number of the documents in the corups} {number of documents in the corups contain the term}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame(columns=['df', 'idf'])\n",
    "for i in range(len(tf)):\n",
    "    in_term = tf.iloc[i].values.sum()\n",
    "\n",
    "    tdf.loc[i, 'df'] = in_term\n",
    "\n",
    "    tdf.loc[i, 'idf'] = math.log10(10 / (float(in_term)))\n",
    "    \n",
    "tdf.index=tf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          df       idf\n",
       "fear       3  0.522879\n",
       "angels     3  0.522879\n",
       "caeser     5   0.30103\n",
       "tread      4   0.39794\n",
       "fools      4   0.39794\n",
       "brutus     3  0.522879\n",
       "in         4   0.39794\n",
       "antony     3  0.522879\n",
       "to         4   0.39794\n",
       "rush       4   0.39794\n",
       "mercy      5   0.30103\n",
       "worser     4   0.39794\n",
       "cleopatra  1       1.0\n",
       "where      4   0.39794\n",
       "calpurnia  1       1.0"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF.IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf.multiply(tdf['idf'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>doc6</th>\n",
       "      <th>doc7</th>\n",
       "      <th>doc8</th>\n",
       "      <th>doc9</th>\n",
       "      <th>doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
       "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
       "angels          0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
       "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
       "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "fools           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "brutus     0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
       "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "antony     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
       "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "mercy       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
       "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
       "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
       "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
       "\n",
       "               doc8      doc9     doc10  \n",
       "fear       0.522879       0.0  0.522879  \n",
       "angels     0.522879  0.522879       0.0  \n",
       "caeser          0.0       0.0       0.0  \n",
       "tread       0.39794   0.39794   0.39794  \n",
       "fools       0.39794   0.39794   0.39794  \n",
       "brutus          0.0       0.0       0.0  \n",
       "in          0.39794   0.39794   0.39794  \n",
       "antony          0.0       0.0       0.0  \n",
       "to          0.39794   0.39794   0.39794  \n",
       "rush        0.39794   0.39794   0.39794  \n",
       "mercy           0.0       0.0       0.0  \n",
       "worser          0.0       0.0       0.0  \n",
       "cleopatra       0.0       0.0       0.0  \n",
       "where       0.39794   0.39794   0.39794  \n",
       "calpurnia       0.0       0.0       0.0  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_articles(q, df):\n",
    "    print(\"query:\", q)\n",
    "    # Convert the query become a vector\n",
    "    q = [q]\n",
    "    q_vec = vectorizer.transform(q).toarray().reshape(df.shape[0],)\n",
    "\n",
    "    sim = {}  # Calculate the similarity\n",
    "    for i in range(10):\n",
    "        sim[i] = np.dot(df.loc[:, i].values, q_vec) / np.linalg.norm(df.loc[:, i]) * np.linalg.norm(q_vec)\n",
    "\n",
    "    # Sort the values \n",
    "    sim_sorted = sorted(sim.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Print the articles and their similarity values\n",
    "    for doc, score in sim_sorted:\n",
    "        if score > 0.5:\n",
    "            print(\"Similarity value:\", score)\n",
    "            print(\"The article is:\", doc)\n",
    "\n",
    "    # print(\"Similarity value:\", sim_sorted[0][1])\n",
    "    # print(\"sim =\", sim_sorted[0])\n",
    "    # print(\"doc =\", documents)\n",
    "    # print(\"The article is:\", documents[sim_sorted[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: antony brutus\n",
      "Similarity value: 0.6707495990011653\n",
      "The article is: 1\n",
      "Similarity value: 0.5835428051584892\n",
      "The article is: 0\n"
     ]
    }
   ],
   "source": [
    "q1 = 'antony brutus' # Call the function\n",
    "get_similar_articles(q1, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('python_10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b35187bd8e81c46a491b0701dacbc6455fb6bb49fda2ea4057c13cf77d84decb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
